{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import used library\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from google.colab import drive\n",
        "import shutil"
      ],
      "metadata": {
        "id": "a-Y221HOjYHT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awnprI1SIQnp",
        "outputId": "871e63dd-e635-4106-d4da-a82bf3f1bdc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dhoogla/nftoniotv2/versions/2\n"
          ]
        }
      ],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dhoogla/nftoniotv2\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the Parquet file\n",
        "parquet_file_path = f\"{path}/NF-ToN-IoT-V2.parquet\"\n",
        "\n",
        "# Load the Parquet file into a pandas DataFrame\n",
        "full_df = pd.read_parquet(parquet_file_path)\n",
        "\n",
        "# Replace inf and -inf with NaN\n",
        "full_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with any NaN values\n",
        "full_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "1Lk6jcCn42ZX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constant values\n",
        "# calculate sampling step\n",
        "final_sample_amount = 5000\n",
        "sampling_step = 13135881 // final_sample_amount"
      ],
      "metadata": {
        "id": "I9xl-VscjtZ_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of primary data set is {full_df.shape}\")\n",
        "print(f\"The number of samples in main data set is equal to: {len(full_df)}\")"
      ],
      "metadata": {
        "id": "EHGVsbBGJth4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd062a2e-ba1f-4dbf-cc5c-fd84f81a5c37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of primary data set is (13135881, 43)\n",
            "The number of samples in main data set is equal to: 13135881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming full_df is your existing DataFrame\n",
        "# Create a new DataFrame with rows at multiple indices of sampling_step\n",
        "shorter_df = full_df.iloc[range(0, len(full_df), sampling_step)]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "shorter_df.to_csv('shorter dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "j8hxkN1P2Iy8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of secondary data set is {shorter_df.shape}\")\n",
        "print(f\"The number of samples in shortened data set is equal to: {len(shorter_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwR08AFmOFhi",
        "outputId": "b9bbdc6a-4a6e-4aa4-e475-855ce0572828"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of secondary data set is (5001, 43)\n",
            "The number of samples in shortened data set is equal to: 5001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming shorter_df is your DataFrame\n",
        "# Get the last column name (assuming it's the label column)\n",
        "label_column = full_df.columns[-1]\n",
        "\n",
        "# Count occurrences of each label\n",
        "label_counts = full_df[label_column].value_counts()\n",
        "\n",
        "# Calculate percentages\n",
        "label_percentages = (label_counts / len(full_df)) * 100\n",
        "\n",
        "# Create a summary DataFrame\n",
        "summary_df = pd.DataFrame({\n",
        "    'Count': label_counts,\n",
        "    'Percentage': label_percentages\n",
        "})\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary of full data set\")\n",
        "print(summary_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqxNdlUeOxQp",
        "outputId": "902e44b3-89b1-4c11-935a-03fd247f8fe8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of full data set\n",
            "              Count  Percentage\n",
            "Attack                         \n",
            "Benign      3601284   27.415626\n",
            "scanning    3002169   22.854721\n",
            "xss         2449955   18.650862\n",
            "ddos        1746590   13.296329\n",
            "password     993718    7.564913\n",
            "injection    660467    5.027961\n",
            "dos          654359    4.981463\n",
            "backdoor      16259    0.123775\n",
            "mitm           7723    0.058793\n",
            "ransomware     3357    0.025556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming shorter_df is your DataFrame\n",
        "# Get the last column name (assuming it's the label column)\n",
        "label_column = shorter_df.columns[-1]\n",
        "\n",
        "# Count occurrences of each label\n",
        "label_counts = shorter_df[label_column].value_counts()\n",
        "\n",
        "# Calculate percentages\n",
        "label_percentages = (label_counts / len(shorter_df)) * 100\n",
        "\n",
        "# Create a summary DataFrame\n",
        "summary_df = pd.DataFrame({\n",
        "    'Count': label_counts,\n",
        "    'Percentage': label_percentages\n",
        "})\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary of shortened data set\")\n",
        "print(summary_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO-WiKbDOKjp",
        "outputId": "93d4892d-381e-4fac-e4f3-0f9779adc1bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of shortened data set\n",
            "            Count  Percentage\n",
            "Attack                       \n",
            "Benign       1365   27.294541\n",
            "scanning     1151   23.015397\n",
            "xss           924   18.476305\n",
            "ddos          669   13.377325\n",
            "password      375    7.498500\n",
            "injection     262    5.238952\n",
            "dos           245    4.899020\n",
            "backdoor        5    0.099980\n",
            "mitm            3    0.059988\n",
            "ransomware      2    0.039992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print one row of the dataset\n",
        "print(shorter_df.iloc[658])  # Prints example row of the DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-NufqrTPlPq",
        "outputId": "3f5b3cef-af4e-4def-cf94-4507bad4de3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L4_SRC_PORT                       21457\n",
            "L4_DST_PORT                       26963\n",
            "PROTOCOL                              6\n",
            "L7_PROTO                            0.0\n",
            "IN_BYTES                             48\n",
            "IN_PKTS                               1\n",
            "OUT_BYTES                             0\n",
            "OUT_PKTS                              0\n",
            "TCP_FLAGS                             2\n",
            "CLIENT_TCP_FLAGS                      2\n",
            "SERVER_TCP_FLAGS                      0\n",
            "FLOW_DURATION_MILLISECONDS            0\n",
            "DURATION_IN                           0\n",
            "DURATION_OUT                          0\n",
            "MIN_TTL                               0\n",
            "MAX_TTL                               0\n",
            "LONGEST_FLOW_PKT                     48\n",
            "SHORTEST_FLOW_PKT                    48\n",
            "MIN_IP_PKT_LEN                        0\n",
            "MAX_IP_PKT_LEN                       48\n",
            "SRC_TO_DST_SECOND_BYTES            48.0\n",
            "DST_TO_SRC_SECOND_BYTES             0.0\n",
            "RETRANSMITTED_IN_BYTES                0\n",
            "RETRANSMITTED_IN_PKTS                 0\n",
            "RETRANSMITTED_OUT_BYTES               0\n",
            "RETRANSMITTED_OUT_PKTS                0\n",
            "SRC_TO_DST_AVG_THROUGHPUT        384000\n",
            "DST_TO_SRC_AVG_THROUGHPUT             0\n",
            "NUM_PKTS_UP_TO_128_BYTES              1\n",
            "NUM_PKTS_128_TO_256_BYTES             0\n",
            "NUM_PKTS_256_TO_512_BYTES             0\n",
            "NUM_PKTS_512_TO_1024_BYTES            0\n",
            "NUM_PKTS_1024_TO_1514_BYTES           0\n",
            "TCP_WIN_MAX_IN                     4096\n",
            "TCP_WIN_MAX_OUT                       0\n",
            "ICMP_TYPE                             0\n",
            "ICMP_IPV4_TYPE                        0\n",
            "DNS_QUERY_ID                          0\n",
            "DNS_QUERY_TYPE                        0\n",
            "DNS_TTL_ANSWER                        0\n",
            "FTP_COMMAND_RET_CODE                  0\n",
            "Label                                 1\n",
            "Attack                         scanning\n",
            "Name: 1728566, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming shorter_df is your DataFrame\n",
        "# Split the DataFrame into training and testing sets\n",
        "train_df, test_df = train_test_split(shorter_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to calculate label percentages\n",
        "def label_percentage(df):\n",
        "    label_column = df.columns[-1]  # Assuming the last column is the label column\n",
        "    label_counts = df[label_column].value_counts()\n",
        "    percentages = (label_counts / len(df)) * 100\n",
        "    return pd.DataFrame({'Count': label_counts, 'Percentage': percentages})\n",
        "\n",
        "# Calculate percentages for training and testing sets\n",
        "train_summary = label_percentage(train_df)\n",
        "test_summary = label_percentage(test_df)\n",
        "\n",
        "# Print the summaries\n",
        "print(\"Training Set Label Summary:\")\n",
        "print(train_summary)\n",
        "\n",
        "print(\"\\nTesting Set Label Summary:\")\n",
        "print(test_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSoxuvx-Pz7R",
        "outputId": "37642711-0ff7-4c00-d7dd-46027fdd5e59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Label Summary:\n",
            "            Count  Percentage\n",
            "Attack                       \n",
            "Benign       1105      27.625\n",
            "scanning      911      22.775\n",
            "xss           747      18.675\n",
            "ddos          531      13.275\n",
            "password      295       7.375\n",
            "injection     206       5.150\n",
            "dos           196       4.900\n",
            "backdoor        5       0.125\n",
            "ransomware      2       0.050\n",
            "mitm            2       0.050\n",
            "\n",
            "Testing Set Label Summary:\n",
            "           Count  Percentage\n",
            "Attack                      \n",
            "Benign       260   25.974026\n",
            "scanning     240   23.976024\n",
            "xss          177   17.682318\n",
            "ddos         138   13.786214\n",
            "password      80    7.992008\n",
            "injection     56    5.594406\n",
            "dos           49    4.895105\n",
            "mitm           1    0.099900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def min_max_normalize(train_df, test_df):\n",
        "    \"\"\"\n",
        "    Normalize the training and testing datasets using Min-Max normalization.\n",
        "\n",
        "    Parameters:\n",
        "    - train_df: DataFrame containing the training data.\n",
        "    - test_df: DataFrame containing the testing data.\n",
        "\n",
        "    Returns:\n",
        "    - normalized_train_df: DataFrame with normalized training data.\n",
        "    - normalized_test_df: DataFrame with normalized testing data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a MinMaxScaler object\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Separate features from labels in the training set\n",
        "    train_features = train_df.iloc[:, :-2]  # All columns except the last two\n",
        "    train_labels = train_df.iloc[:, -2:]     # Last two columns (labels)\n",
        "\n",
        "    # Fit the scaler on the training features and transform them\n",
        "    normalized_train_features = scaler.fit_transform(train_features)\n",
        "\n",
        "    # Create a new DataFrame for normalized training data\n",
        "    normalized_train_df = pd.DataFrame(normalized_train_features, columns=train_features.columns)\n",
        "\n",
        "    # Add back the labels to the normalized training DataFrame\n",
        "    normalized_train_df = pd.concat([normalized_train_df, train_labels.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Separate features from labels in the testing set\n",
        "    test_features = test_df.iloc[:, :-2]  # All columns except the last two\n",
        "    test_labels = test_df.iloc[:, -2:]     # Last two columns (labels)\n",
        "\n",
        "    # Transform the testing features using the same scaler\n",
        "    normalized_test_features = scaler.transform(test_features)\n",
        "\n",
        "    # Create a new DataFrame for normalized testing data\n",
        "    normalized_test_df = pd.DataFrame(normalized_test_features, columns=test_features.columns)\n",
        "\n",
        "    # Add back the labels to the normalized testing DataFrame\n",
        "    normalized_test_df = pd.concat([normalized_test_df, test_labels.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    return normalized_train_df, normalized_test_df\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have your train and test DataFrames ready as train_df and test_df\n",
        "# normalized_train, normalized_test = normalize_datasets(train_df, test_df)\n",
        "\n",
        "# Normalize both training and testing sets\n",
        "train_normalized, test_normalized = min_max_normalize(train_df, test_df)"
      ],
      "metadata": {
        "id": "IjxdQwfHQNoJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print one row of the dataset\n",
        "print(train_normalized.iloc[658])  # Prints example row of the DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBjujo0nQeuI",
        "outputId": "00e9909c-1501-4ffb-e4b5-be51140021b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L4_SRC_PORT                     0.67328\n",
            "L4_DST_PORT                    0.006762\n",
            "PROTOCOL                       0.087719\n",
            "L7_PROTO                        0.39738\n",
            "IN_BYTES                       0.000186\n",
            "IN_PKTS                        0.000183\n",
            "OUT_BYTES                      0.000591\n",
            "OUT_PKTS                        0.01476\n",
            "TCP_FLAGS                      0.463415\n",
            "CLIENT_TCP_FLAGS               0.439024\n",
            "SERVER_TCP_FLAGS               0.612903\n",
            "FLOW_DURATION_MILLISECONDS      0.99992\n",
            "DURATION_IN                    0.201031\n",
            "DURATION_OUT                   0.332687\n",
            "MIN_TTL                         0.25098\n",
            "MAX_TTL                         0.25098\n",
            "LONGEST_FLOW_PKT               0.007529\n",
            "SHORTEST_FLOW_PKT              0.058252\n",
            "MIN_IP_PKT_LEN                 0.403101\n",
            "MAX_IP_PKT_LEN                 0.007529\n",
            "SRC_TO_DST_SECOND_BYTES             0.0\n",
            "DST_TO_SRC_SECOND_BYTES        0.000002\n",
            "RETRANSMITTED_IN_BYTES              0.0\n",
            "RETRANSMITTED_IN_PKTS               0.0\n",
            "RETRANSMITTED_OUT_BYTES             0.0\n",
            "RETRANSMITTED_OUT_PKTS              0.0\n",
            "SRC_TO_DST_AVG_THROUGHPUT           0.0\n",
            "DST_TO_SRC_AVG_THROUGHPUT           0.0\n",
            "NUM_PKTS_UP_TO_128_BYTES        0.00005\n",
            "NUM_PKTS_128_TO_256_BYTES           0.0\n",
            "NUM_PKTS_256_TO_512_BYTES           0.0\n",
            "NUM_PKTS_512_TO_1024_BYTES          0.0\n",
            "NUM_PKTS_1024_TO_1514_BYTES         0.0\n",
            "TCP_WIN_MAX_IN                 0.445563\n",
            "TCP_WIN_MAX_OUT                0.441901\n",
            "ICMP_TYPE                           0.0\n",
            "ICMP_IPV4_TYPE                      0.0\n",
            "DNS_QUERY_ID                        0.0\n",
            "DNS_QUERY_TYPE                      0.0\n",
            "DNS_TTL_ANSWER                      0.0\n",
            "FTP_COMMAND_RET_CODE                0.0\n",
            "Label                                 1\n",
            "Attack                             ddos\n",
            "Name: 658, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save normalized training and testing sets to CSV files\n",
        "train_normalized.to_csv('normalized_train.csv', index=False)\n",
        "test_normalized.to_csv('normalized_test.csv', index=False)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Move the CSV files to Google Drive\n",
        "drive_path = '/content/drive/MyDrive/IDS data sets/'\n",
        "shutil.move('normalized_train.csv', drive_path + 'NF-ToN-IoT-V2_' + str(final_sample_amount) + ' samples_minmax_normalized_train.csv')\n",
        "shutil.move('normalized_test.csv', drive_path + 'NF-ToN-IoT-V2_' + str(final_sample_amount) + ' samples_minmax_normalized_test.csv')\n",
        "\n",
        "print(\"Files have been uploaded to Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMh8DiijQUyp",
        "outputId": "11b86565-dde5-4214-bfad-e5e2940d87ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Files have been uploaded to Google Drive.\n"
          ]
        }
      ]
    }
  ]
}